import numpy as np
import pandas as pd
import seaborn as sns
import scipy.stats as stats
import statsmodels.api as sm
import category_encoders as ce
import matplotlib.pyplot as plt

from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.tools.tools import add_constant
from prediction.statistics_analysis import analyze_distribution, analyze_homoscedasticity
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import cross_val_score, train_test_split, KFold
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


def plot_boxplots_and_detect_outliers(df, numerical_cols):
    plt.figure(figsize=(12, 8))
    sns.boxplot(data=df[numerical_cols])
    plt.title('Boxplot das Vari√°veis Num√©ricas')
    plt.xticks(rotation=45)
    plt.show()

    outliers = {}
    for col in numerical_cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_limit = Q1 - 1.5 * IQR
        upper_limit = Q3 + 1.5 * IQR
        outliers[col] = df[(df[col] < lower_limit) | (df[col] > upper_limit)]
        if not outliers[col].empty:
            print(f"Outliers em {col}:")
            print(outliers[col][col])
            print("\n")
    return outliers

def remove_outliers_using_iqr(df, cols):
    for col in cols:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        
        lower_limit = Q1 - 1.5 * IQR
        upper_limit = Q3 + 1.5 * IQR
        df = df[(df[col] >= lower_limit) & (df[col] <= upper_limit)]
        
    return df

def runLinearRegressor(df: pd.DataFrame):
    """ ************* Carregamento e Vis√£o Geral dos Dados  ************* """

    print(df.head())
    print(df.info())

    """ ****************************************************************** """
    """ ******************** Estat√≠sticas Descritivas ******************** """

    # print(df.describe())

    """ ****************************************************************** """
    """ ******************* Limpeza e Pr√©-processamento ****************** """
    
    # Conforme Hair (2009), √© essencial garantir que os dados estejam limpos
    # antes de prosseguir com a an√°lise. A remo√ß√£o de dados faltantes (NaN)
    # √© um passo fundamental nesse processo.
    df = df.dropna()
    df = df.drop(['Title'], axis=1)

    """ ****************************************************************** """
    """ ***************** Transforma√ß√µes de Vari√°veis ******************** """
    # Hair (2009) discute a import√¢ncia de verificar as premissas da regress√£o linear,
    # como a normalidade dos res√≠duos. Transformar vari√°veis com distribui√ß√µes
    # muito assim√©tricas (como visto nos histogramas) pode ajudar a atender a essa premissa.
    # A transforma√ß√£o logar√≠tmica √© uma das mais comuns para reduzir a assimetria positiva.
    df['Public_Total'] = df['Public_Total'].apply(lambda x: np.log(x + 1))
    df['Days_in_exibithion'] = df['Days_in_exibithion'].apply(lambda x: np.log(x + 1))

    # plot_boxplots_and_detect_outliers(df, [item for item in numerical_cols if item != "Public_Total"])
    # df = remove_outliers_using_iqr(df, numerical_cols)
    # plot_boxplots_and_detect_outliers(df, [item for item in numerical_cols if item != "Public_Total"])

    """ ****************************************************************** """
    """ **************** Feature Engineering e Sele√ß√£o ******************* """
    # A cria√ß√£o de vari√°veis a partir de outras existentes pode melhorar o modelo.
    # No entanto, vari√°veis de intera√ß√£o baseadas em colunas categ√≥ricas
    # devem ser criadas AP√ìS a codifica√ß√£o dessas colunas.
    
    # Transforma√ß√£o de data em features ciclicas e mensais para capturar sazonalidade.
    df.loc[:, 'Month'] = df['Release_Date'].dt.month
    df.loc[:, 'Day_of_Week_sin'] = np.sin(2 * np.pi * df['Release_Date'].dt.dayofweek / 7)
    
    # Remo√ß√£o de colunas que n√£o ser√£o mais √∫teis ou que foram combinadas.
    # A multicolinearidade √© um problema s√©rio na regress√£o, e o VIF (Variance Inflation Factor)
    # √© a principal medida para diagnostic√°-la (Hair, 2009). 'Runtime' foi previamente
    # identificado com alto VIF, indicando que sua informa√ß√£o j√° est√° contida em outras vari√°veis.
    COLS_TO_DROP = ['Release_Date', 'Runtime']
    df = df.drop(COLS_TO_DROP, axis=1)

    """ ****************************************************************** """
    """ ***************** Separa√ß√£o em treino e teste ******************** """
    # Este √© um dos passos mais cr√≠ticos. Segundo Hair (2009) e todas as boas pr√°ticas
    # de modelagem, devemos dividir os dados ANTES de qualquer transforma√ß√£o que aprenda
    # par√¢metros com os dados (como encoding e scaling). Isso previne o "data leakage",
    # garantindo que a avalia√ß√£o do modelo seja feita em dados verdadeiramente "n√£o vistos".
    X = df.drop(['Public_Total'], axis=1)
    y = df['Public_Total']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    X_train = pd.DataFrame(X_train, columns=X.columns)
    X_test = pd.DataFrame(X_test, columns=X.columns)
    
    """ ****************************************************************** """
    """ ************ Codifica√ß√£o, Feature Engineering e Padroniza√ß√£o *********** """

    # 1. Identificando colunas para as transforma√ß√µes corretas
    categorical_cols = X_train.select_dtypes(include=['object', 'category']).columns.tolist()

    # 2. Target Encoding para vari√°veis categ√≥ricas.
    # O encoder √© "treinado" (fit) APENAS no conjunto de treino e depois aplicado em ambos.
    target_encoder = ce.TargetEncoder(cols=categorical_cols)
    X_train_encoded = target_encoder.fit_transform(X_train, y_train)
    X_test_encoded = target_encoder.transform(X_test)
    
    # 3. Feature Engineering (P√≥s-Codifica√ß√£o)
    # Agora que as colunas categ√≥ricas s√£o num√©ricas, podemos criar intera√ß√µes.
    # Hair (2009) discute o uso de intera√ß√µes para capturar efeitos complexos.
    X_train_encoded['Ratting_Movie'] = X_train_encoded['Vote_Average'] * X_train_encoded['IMDB_Rating']
    X_train_encoded['Interaction_Cast'] = X_train_encoded['Cast_1'] * X_train_encoded['Cast_2'] * X_train_encoded['Cast_3'] * X_train_encoded['Director_1']

    X_test_encoded['Ratting_Movie'] = X_test_encoded['Vote_Average'] * X_test_encoded['IMDB_Rating']
    X_test_encoded['Interaction_Cast'] = X_test_encoded['Cast_1'] * X_test_encoded['Cast_2'] * X_test_encoded['Cast_3'] * X_test_encoded['Director_1']

    # 4. Removendo as colunas originais que formaram as intera√ß√µes
    cols_to_drop_post_encoding = ['Vote_Average', 'IMDB_Rating', 'Cast_1', 'Cast_2', 'Cast_3', 'Director_1']
    X_train_final = X_train_encoded.drop(columns=cols_to_drop_post_encoding)
    X_test_final = X_test_encoded.drop(columns=cols_to_drop_post_encoding)

    # 5. Padroniza√ß√£o das vari√°veis
    # O scaler √© "treinado" (fit) APENAS no conjunto de treino.
    # Hair (2009) recomenda a padroniza√ß√£o para comparar a import√¢ncia dos coeficientes.
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train_final)
    X_test_scaled = scaler.transform(X_test_final)
    
    # Recriando os DataFrames com as colunas e √≠ndices corretos ap√≥s a padroniza√ß√£o
    X_train_final = pd.DataFrame(X_train_scaled, columns=X_train_final.columns, index=X_train_final.index)
    X_test_final = pd.DataFrame(X_test_scaled, columns=X_test_final.columns, index=X_test_final.index)

    """ ****************************************************************** """
    """ ***************** An√°lise de Multicolinearidade ****************** """
    
    # A verifica√ß√£o do VIF deve ser feita nos dados de treino processados,
    # pois √© com eles que o modelo ser√° constru√≠do.
    vif_data = pd.DataFrame()
    vif_data["Variable"] = X_train_final.columns
    vif_data["VIF"] = [variance_inflation_factor(X_train_final.values, i) for i in range(X_train_final.shape[1])]
    print("\nFator de Infla√ß√£o de Vari√¢ncia (VIF) nos dados de treino:")
    print(vif_data)
    print("_____________________________________________________\n")

    """ ****************************************************************** """
    """ ***** Treinamento e avalia√ß√£o do modelo com cross-validation ***** """

    # O Statsmodels √© excelente para infer√™ncia estat√≠stica, fornecendo um resumo
    # detalhado do modelo, incluindo p-valores para cada coeficiente, o que √©
    # essencial para a an√°lise de signific√¢ncia (Hair, 2009).
    X_train_sm = sm.add_constant(X_train_final) # Adicionar o intercepto para o OLS
    model_sm = sm.OLS(y_train, X_train_sm).fit()
    print(model_sm.summary())

    # O Scikit-learn √© mais focado em previs√£o. Usaremos para treinar o modelo final
    # e fazer as predi√ß√µes no conjunto de teste.
    model = LinearRegression()
    model.fit(X_train_final, y_train)
    y_pred = model.predict(X_test_final)

    """ ****************************************************************** """
    """ ****************** Equa√ß√£o da Regress√£o Linear ******************* """

    coeficientes = model.coef_
    interceptor = model.intercept_

    print("\nüìå Equa√ß√£o da Regress√£o Linear:")
    equation = f"Public_Total = {interceptor:.4f} "
    for feature, coef in zip(X_train_final.columns, coeficientes):
        equation += f"+ ({coef:.4f} * {feature}) "
    
    print(equation)
    
    """ ****************************************************************** """
    """ ********************* Avalia√ß√£o do modelo ************************ """
    # Avaliamos o modelo no conjunto de teste para ter uma medida de seu
    # poder de generaliza√ß√£o. R¬≤ indica a propor√ß√£o da vari√¢ncia na vari√°vel
    # dependente que √© previs√≠vel a partir das vari√°veis independentes.
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # A valida√ß√£o cruzada (Cross-Validation) fornece uma estimativa mais robusta
    # do desempenho do modelo do que uma √∫nica divis√£o treino-teste (Hair, 2009).
    # Ela treina e avalia o modelo m√∫ltiplas vezes em diferentes subconjuntos dos dados.
    # IMPORTANTE: Para evitar data leakage na valida√ß√£o cruzada com o TargetEncoder,
    # seria necess√°rio criar um pipeline mais complexo. Por simplicidade, faremos a CV
    # nos dados j√° processados do conjunto de treino, mas o ideal seria encapsular
    # o encoder e o scaler em um Pipeline do scikit-learn.
    scores = cross_val_score(model, X_train_final, y_train, cv=5, scoring='r2')

    print(f"\nüìä Resultados da Regress√£o Linear:")
    print(f"üîπ Mean Squared Error (MSE) no teste: {mse:.2f}")
    print(f"üîπ R¬≤ no teste: {r2:.2f}")
    print(f"üîπ Cross-Validation R¬≤ Scores (no treino): {scores}")
    print(f"üîπ M√©dia dos R¬≤ (CV no treino): {scores.mean():.3f}")

    """ ****************************************************************** """
    """ ******************* Diagn√≥stico de res√≠duos ********************** """
    # A an√°lise de res√≠duos √© fundamental para verificar as premissas do modelo.
    # O gr√°fico de res√≠duos vs. valores previstos ajuda a identificar heterocedasticidade
    # (a vari√¢ncia dos erros n√£o √© constante). O ideal √© uma nuvem de pontos aleat√≥ria
    # em torno da linha zero, sem padr√µes (funil, curva, etc.).
    residuals = y_test - y_pred
    plt.scatter(y_pred, residuals)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.title('Res√≠duos vs Valores Previstos (no Teste)')
    plt.xlabel('Valores Previstos')
    plt.ylabel('Res√≠duos')
    plt.show()

    # O Q-Q plot (Gr√°fico de Probabilidade Normal) compara a distribui√ß√£o dos res√≠duos
    # com uma distribui√ß√£o normal te√≥rica. Se os pontos seguem a linha diagonal,
    # a premissa de normalidade dos res√≠duos √© satisfeita.
    stats.probplot(residuals, dist="norm", plot=plt)
    plt.show()

    """ ****************************************************************** """
    
if __name__ == "__main__":
    # Carregando os dados para execu√ß√£o do script
    DATA_PATH           = "data/output"
    FINAL_PATH          = f"{DATA_PATH}/DATAS/FINAL_DATABASE"
    FINAL_FILE_NAME     = "MOVIES"
    DF_FILE = FINAL_PATH + "/" + FINAL_FILE_NAME + ".parquet"

    df = pd.read_parquet(DF_FILE)
    runLinearRegressor(df)





    // ... existing code ...
    # Treinando o pipeline
    model_pipeline.fit(X_train, y_train)
    print("Pipeline de pr√©-processamento e treinamento conclu√≠do.")