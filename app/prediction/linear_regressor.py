import pandas as pd
import numpy as np
import statsmodels.api as sm
import category_encoders as ce
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor

def runLinearRegressor(df: pd.DataFrame):
    """
    Executa um fluxo completo de regress√£o linear com base no arquivo MOVIES.csv,
    seguindo as melhores pr√°ticas de pr√©-processamento e avalia√ß√£o de modelo.
    """
    # 1. Carregamento e Limpeza Inicial dos Dados
    df = df.dropna().drop_duplicates()
    df = df.drop(['Title'], axis=1, errors='ignore')
    df = df.drop(['budget'], axis=1, errors='ignore')
    print(f"Formato ap√≥s limpeza inicial (dropna, drop_duplicates): {df.shape}")

    # 2. Pr√©-processamento e Feature Engineering
    # Converte a data de lan√ßamento, extrai features e remove a coluna original
    df['Release_Date'] = pd.to_datetime(df['Release_Date'], errors='coerce')
    df = df.dropna(subset=['Release_Date'])
    df['Month'] = df['Release_Date'].dt.month
    df['Day_of_Week_sin'] = np.sin(2 * np.pi * df['Release_Date'].dt.dayofweek / 7)
    df = df.drop(['Release_Date'], axis=1)

    # Transforma√ß√£o logar√≠tmica da vari√°vel alvo para normalizar a distribui√ß√£o e reduzir o impacto de outliers
    # np.log1p(x) √© equivalente a np.log(x + 1), mais est√°vel para valores pequenos
    df['Public_Total'] = np.log1p(df['Public_Total'])

    # 3. Separa√ß√£o em Conjuntos de Treino e Teste
    # Este √© um passo crucial para evitar data leakage
    X = df.drop('Public_Total', axis=1)
    y = df['Public_Total']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    # Garantindo que os conjuntos de treino e teste permane√ßam como DataFrames
    X_train = pd.DataFrame(X_train, columns=X.columns)
    X_test = pd.DataFrame(X_test, columns=X.columns)
    
    print(f"Dados divididos em treino ({X_train.shape[0]} amostras) e teste ({X_test.shape[0]} amostras).")

    # 4. Codifica√ß√£o e Padroniza√ß√£o
    # Identifica as colunas por tipo para aplicar as transforma√ß√µes corretas
    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()
    
    # Target Encoding para vari√°veis categ√≥ricas
    # O encoder aprende a m√©dia da vari√°vel alvo para cada categoria APENAS nos dados de treino
    encoder = ce.TargetEncoder(cols=categorical_cols)
    X_train_encoded = encoder.fit_transform(X_train, y_train)
    X_test_encoded = encoder.transform(X_test)

    # Padroniza√ß√£o (Standard Scaling)
    # Coloca todas as vari√°veis na mesma escala (m√©dia 0, desvio padr√£o 1)
    scaler = StandardScaler()
    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_encoded), columns=X_train_encoded.columns, index=X_train_encoded.index)
    X_test_scaled = pd.DataFrame(scaler.transform(X_test_encoded), columns=X_test_encoded.columns, index=X_test_encoded.index)
    print("Codifica√ß√£o de vari√°veis categ√≥ricas e padroniza√ß√£o conclu√≠das.")

    # 5. An√°lise de Multicolinearidade (VIF)
    # Hair (2009) recomenda verificar o VIF para garantir que as vari√°veis preditoras n√£o sejam redundantes.
    # Um VIF > 10 √© geralmente considerado um sinal de alta multicolinearidade.
    vif_data = pd.DataFrame()
    vif_data["feature"] = X_train_scaled.columns
    vif_data["VIF"] = [variance_inflation_factor(X_train_scaled.values, i) for i in range(len(X_train_scaled.columns))]
    print("\n--- An√°lise de Fator de Infla√ß√£o de Vari√¢ncia (VIF) ---")
    print(vif_data)

    # 6. Treinamento do Modelo com Statsmodels para An√°lise Inferencial
    X_train_sm = sm.add_constant(X_train_scaled) # Adiciona o intercepto
    model = sm.OLS(y_train, X_train_sm).fit()
    print("\n--- OLS Regression Results ---")
    print(model.summary())

    # 7. Avalia√ß√£o do Modelo no Conjunto de Teste
    X_test_sm = sm.add_constant(X_test_scaled)
    y_pred = model.predict(X_test_sm)

    # Extraindo a equa√ß√£o do modelo treinado
    print("\n--- Equa√ß√£o da Regress√£o Linear ---")
    coefs = model.params
    equation = f"Public_Total = {coefs['const']:.4f} "
    for feature, coef in coefs.drop('const').items():
        equation += f"+ ({coef:.4f} * {feature}) "
    print(equation)

    # Valida√ß√£o Cruzada com Scikit-learn para uma avalia√ß√£o mais robusta do R¬≤ no treino
    lr_model_cv = LinearRegression()
    scores = cross_val_score(lr_model_cv, X_train_scaled, y_train, cv=5, scoring='r2')

    # M√©tricas de avalia√ß√£o
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"\nüìä Resultados da Regress√£o Linear:")
    print(f"üîπ Mean Squared Error (MSE) no teste: {mse:.2f}")
    print(f"üîπ R¬≤ no teste: {r2:.2f}")
    print(f"üîπ Cross-Validation R¬≤ Scores (no treino): {scores}")
    print(f"üîπ M√©dia dos R¬≤ (CV no treino): {scores.mean():.3f}")

    # 8. Diagn√≥stico de Res√≠duos
    # Hair (2009) enfatiza a import√¢ncia de analisar os res√≠duos para validar as premissas da regress√£o.
    residuals = y_test - y_pred
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Gr√°fico de Res√≠duos vs. Valores Previstos: idealmente, pontos aleat√≥rios em torno da linha zero.
    sns.scatterplot(x=y_pred, y=residuals, ax=axes[0], alpha=0.6)
    axes[0].axhline(0, color='red', linestyle='--')
    axes[0].set_title('Gr√°fico de Res√≠duos vs. Valores Previstos')
    axes[0].set_xlabel('Valores Previstos (Log do P√∫blico)')
    axes[0].set_ylabel('Res√≠duos')

    # Gr√°fico Q-Q: idealmente, os pontos devem seguir a linha diagonal vermelha.
    sm.qqplot(residuals, line='s', ax=axes[1])
    axes[1].set_title('Gr√°fico de Probabilidade Normal (Q-Q Plot)')

    plt.tight_layout()
    plt.show()


if __name__ == '__main__':
    runLinearRegressor()
