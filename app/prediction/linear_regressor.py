import pandas as pd
import numpy as np
import statsmodels.api as sm
import category_encoders as ce
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor

def runLinearRegressor(df: pd.DataFrame):
    """
    Executa um fluxo completo de regress√£o linear com base no arquivo MOVIES.csv,
    seguindo as melhores pr√°ticas de pr√©-processamento e avalia√ß√£o de modelo.
    """
    # 1. Carregamento e Limpeza Inicial dos Dados
    df = df.dropna().drop_duplicates()
    df = df.drop(['Title'], axis=1, errors='ignore')
    print(f"Formato ap√≥s limpeza inicial (dropna, drop_duplicates): {df.shape}")

    # ===== PLANO DE A√á√ÉO (ITERA√á√ÉO 2) =====
    # Remo√ß√£o de vari√°veis n√£o significativas e das que causam overfitting para criar um modelo base.
    vars_to_drop = [
        'Runtime', 'Vote_Average', 'IMDB_Rating', 'Month', 'Day_of_Week_sin',
        'Director_1', 'Release_Date', 'budget'
    ]
    df = df.drop(columns=vars_to_drop, errors='ignore')
    print(f"Vari√°veis removidas. Mantendo 'Cast_1, 2, 3' para engenharia de features. Novo formato: {df.shape}")
    
    # Transforma√ß√£o logar√≠tmica da vari√°vel alvo
    df['Public_Total'] = np.log1p(df['Public_Total'])

    # 2. Separa√ß√£o em Conjuntos de Treino e Teste
    X = df.drop('Public_Total', axis=1)
    y = df['Public_Total']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    X_train = pd.DataFrame(X_train, columns=X.columns)
    X_test = pd.DataFrame(X_test, columns=X.columns)
    
    # 3. Engenharia de Features: N√≠veis de Elenco (P√≥s-Split)
    print("Iniciando engenharia de features: N√≠veis de Elenco...")
    # Contar a frequ√™ncia de cada ator APENAS no conjunto de treino
    cast_cols = ['Cast_1', 'Cast_2', 'Cast_3']
    actor_counts = pd.concat([X_train[col] for col in cast_cols]).value_counts()
    
    # Definir os limiares para os tiers (quantis)
    q1 = actor_counts.quantile(0.66) # 66% menos frequentes
    q2 = actor_counts.quantile(0.95) # 95% mais frequentes
    
    def get_actor_tier(actor, counts, q1, q2):
        count = counts.get(actor, 0)
        if count > q2:
            return 3 # Tier 1 (A-Lister)
        elif count > q1:
            return 2 # Tier 2 (Regular)
        else:
            return 1 # Tier 3 (Outros)

    for col in cast_cols:
        X_train[f'{col}_tier'] = X_train[col].apply(lambda x: get_actor_tier(x, actor_counts, q1, q2))
        X_test[f'{col}_tier'] = X_test[col].apply(lambda x: get_actor_tier(x, actor_counts, q1, q2))

    # Criar uma √∫nica feature de "for√ßa do elenco"
    X_train['Cast_Power'] = X_train[[f'{col}_tier' for col in cast_cols]].max(axis=1)
    X_test['Cast_Power'] = X_test[[f'{col}_tier' for col in cast_cols]].max(axis=1)

    # Remover as colunas originais e de tier
    cols_to_drop_post_feature_eng = cast_cols + [f'{col}_tier' for col in cast_cols]
    X_train = X_train.drop(columns=cols_to_drop_post_feature_eng)
    X_test = X_test.drop(columns=cols_to_drop_post_feature_eng)
    print("Feature 'Cast_Power' criada e colunas originais de elenco removidas.")

    print(f"Dados divididos em treino ({X_train.shape[0]} amostras) e teste ({X_test.shape[0]} amostras).")

    # 4. Codifica√ß√£o e Padroniza√ß√£o
    categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()
    
    # Target Encoding para vari√°veis categ√≥ricas
    # O encoder aprende a m√©dia da vari√°vel alvo para cada categoria APENAS nos dados de treino
    encoder = ce.TargetEncoder(cols=categorical_cols)
    X_train_encoded = encoder.fit_transform(X_train, y_train)
    X_test_encoded = encoder.transform(X_test)

    # Padroniza√ß√£o (Standard Scaling)
    # Coloca todas as vari√°veis na mesma escala (m√©dia 0, desvio padr√£o 1)
    scaler = StandardScaler()
    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train_encoded), columns=X_train_encoded.columns, index=X_train_encoded.index)
    X_test_scaled = pd.DataFrame(scaler.transform(X_test_encoded), columns=X_test_encoded.columns, index=X_test_encoded.index)
    print("Codifica√ß√£o de vari√°veis categ√≥ricas e padroniza√ß√£o conclu√≠das.")

    # 5. An√°lise de Multicolinearidade (VIF)
    # Hair (2009) recomenda verificar o VIF para garantir que as vari√°veis preditoras n√£o sejam redundantes.
    # Um VIF > 10 √© geralmente considerado um sinal de alta multicolinearidade.
    vif_data = pd.DataFrame()
    vif_data["feature"] = X_train_scaled.columns
    vif_data["VIF"] = [variance_inflation_factor(X_train_scaled.values, i) for i in range(len(X_train_scaled.columns))]
    print("\n--- An√°lise de Fator de Infla√ß√£o de Vari√¢ncia (VIF) ---")
    print(vif_data)

    # 6. Treinamento do Modelo com Statsmodels para An√°lise Inferencial
    X_train_sm = sm.add_constant(X_train_scaled) # Adiciona o intercepto
    model = sm.OLS(y_train, X_train_sm).fit()
    print("\n--- OLS Regression Results ---")
    print(model.summary())

    # 7. Avalia√ß√£o do Modelo no Conjunto de Teste
    X_test_sm = sm.add_constant(X_test_scaled)
    y_pred = model.predict(X_test_sm)

    # Extraindo a equa√ß√£o do modelo treinado
    print("\n--- Equa√ß√£o da Regress√£o Linear ---")
    coefs = model.params
    equation = f"Public_Total = {coefs['const']:.4f} "
    for feature, coef in coefs.drop('const').items():
        equation += f"+ ({coef:.4f} * {feature}) "
    print(equation)

    # Valida√ß√£o Cruzada com Scikit-learn para uma avalia√ß√£o mais robusta do R¬≤ no treino
    lr_model_cv = LinearRegression()
    scores = cross_val_score(lr_model_cv, X_train_scaled, y_train, cv=5, scoring='r2')

    # M√©tricas de avalia√ß√£o
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"\nüìä Resultados da Regress√£o Linear:")
    print(f"üîπ Mean Squared Error (MSE) no teste: {mse:.2f}")
    print(f"üîπ R¬≤ no teste: {r2:.2f}")
    print(f"üîπ Cross-Validation R¬≤ Scores (no treino): {scores}")
    print(f"üîπ M√©dia dos R¬≤ (CV no treino): {scores.mean():.3f}")

    # 8. Diagn√≥stico de Res√≠duos
    # Hair (2009) enfatiza a import√¢ncia de analisar os res√≠duos para validar as premissas da regress√£o.
    residuals = y_test - y_pred
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Gr√°fico de Res√≠duos vs. Valores Previstos: idealmente, pontos aleat√≥rios em torno da linha zero.
    sns.scatterplot(x=y_pred, y=residuals, ax=axes[0], alpha=0.6)
    axes[0].axhline(0, color='red', linestyle='--')
    axes[0].set_title('Gr√°fico de Res√≠duos vs. Valores Previstos')
    axes[0].set_xlabel('Valores Previstos (Log do P√∫blico)')
    axes[0].set_ylabel('Res√≠duos')

    # Gr√°fico Q-Q: idealmente, os pontos devem seguir a linha diagonal vermelha.
    sm.qqplot(residuals, line='s', ax=axes[1])
    axes[1].set_title('Gr√°fico de Probabilidade Normal (Q-Q Plot)')

    plt.tight_layout()
    plt.show()


if __name__ == '__main__':
    runLinearRegressor()
